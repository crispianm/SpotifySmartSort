{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import matrix\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from get_timbre import get_timbre\n",
    "from evaluation import evaluate_data\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import random\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "parser = ConfigParser()\n",
    "parser.read('./spotify_credentials.cfg')\n",
    "\n",
    "SPOTIPY_CLIENT_ID = parser.get('spotify', 'SPOTIPY_CLIENT_ID')\n",
    "SPOTIPY_CLIENT_SECRET = parser.get('spotify', 'SPOTIPY_CLIENT_SECRET')\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET))\n",
    "\n",
    "user_id = 'czdoifmfngjhvoetavlok9dg5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_ids = ['5odVaQ10ISGhvuakjVGmxp', '0mCV9EHiVXEsbw307lBF25', '4VGvI1dODxGyBop5jFhgfN',\n",
    "                '5pVRL48wvxNRL8lWkxdVCX', '5Kq61WYIbYGLB6dvuTKzZV', '3MO4sQXwvB13TAdiSoG9AR',\n",
    "                '64iSau8h74DkOUG8JVY3W2', '5ZWw4qko5ccxnEIA8blVSq', '35iVxmwsHyJVSdvRasuK8V',\n",
    "                '06LB9aYKvibLEXb4Qf3gHM', '2dfxSJXVFYpZi2YOjgbwRX', '6FwDZbpBnGXBOJ1UwW9lKb',\n",
    "                '44vN1eprBxUdirtb9pCOge', '64mSbvFQYIW547z4zWrEQK', '3VBWC197hTEmayqbDTmvp4',\n",
    "                '2Am8cD0icf62d4dL7NrDTx', '0fjjY976NVJ03tPhxjamcX', '0vzdOGXJBf6SBFeYbwfpnL',\n",
    "                '5JufAIzUR25lgE8zrums4k', '2ppGD3RwccxuPSJZiyZrCm', '4LBHOUvGlk4RtaMbfB5huK',\n",
    "                '1VJZKBsulYCry6QpSoW5mG', '0dnsYgOOtfsOg78qLrZEAv', '5KtPLkVfM18fVQ4puapK98',\n",
    "                '51eXnQHgNcFw7xGllU5kCf', '23x3CI4Cncf6BpSnIeZlF7', '1rDhjtHJkAIlUWgJlxQSRF',\n",
    "                '5cS1vW9gzr2lLFZ0XpkmfD', '2xxXRaeMZSoAiUslTqbB7S', '0Gx1JfJVTkWSfCcTkMgJiA',\n",
    "                ]\n",
    "random_y = ''\n",
    "\n",
    "# playlist_ids = ['5odVaQ10ISGhvuakjVGmxp']\n",
    "# random_y = ''\n",
    "\n",
    "# playlist_ids = ['a','b','c','d']\n",
    "# random_y = 'random_'\n",
    "\n",
    "columns_to_remove = ['id', 'track_title', 'album_title', 'album_artist',\n",
    "                    'track_number', 'total_tracks', 'key', 'mode',\n",
    "                    'duration_ms', 'time_signature']\n",
    "\n",
    "evaluation_vector_titles = ['keyTransition', 'tempoTransition', 'trackNumTransition', 'loudnessTransition', 'timbreTransition',\n",
    "                            'danceabilityTransition', 'energyTransition', 'speechinessTransition','acousticnessTransition',\n",
    "                            'instrumentalnessTransition', 'livenessTransition', 'valenceTransition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all track data (has been run, no longer needed)\n",
    "\n",
    "# x = 1\n",
    "# for playlist_id in playlist_ids:\n",
    "#     print('Running playlist ' + playlist_id)\n",
    "\n",
    "#     # Get track data\n",
    "    \n",
    "#     results = sp.playlist_tracks(playlist_id)\n",
    "#     tracks = results['items']\n",
    "#     track_ids = []\n",
    "#     for track in tracks:\n",
    "#         track_ids.append(track['track']['id'])\n",
    "\n",
    "#     columns_to_remove = ['analysis_url', 'type', 'uri', 'track_href']\n",
    "#     headings = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "#                 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "#                 'id', 'duration_ms', 'time_signature', 'track_title', 'album_title',\n",
    "#                 'album_artist', 'track_number', 'total_tracks']\n",
    "\n",
    "#     playlist_data = pd.DataFrame(columns=headings)\n",
    "#     playlist_length = len(track_ids)\n",
    "\n",
    "#     i = 0\n",
    "#     for track in track_ids:\n",
    "#         results = sp.audio_features(track)\n",
    "#         if results[0]: \n",
    "#             features = results[0]\n",
    "        \n",
    "#         features_matrix = pd.DataFrame.from_records(features, index=[0])\n",
    "        \n",
    "#         # Remove unneeded columns\n",
    "#         features_matrix.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
    "\n",
    "#         # Add track info\n",
    "#         features_matrix['track_title'] = tracks[i]['track']['name']\n",
    "#         features_matrix['album_title'] = tracks[i]['track']['album']['name']\n",
    "#         features_matrix['album_artist'] = tracks[i]['track']['album']['artists'][0]['name']\n",
    "\n",
    "#         # Add track number and total tracks\n",
    "#         features_matrix['track_number'] = tracks[i]['track']['track_number']\n",
    "#         features_matrix['total_tracks'] = playlist_length\n",
    "\n",
    "#         playlist_data = pd.concat([playlist_data, features_matrix])\n",
    "#         i += 1\n",
    "\n",
    "#     playlist_data = playlist_data.reset_index(drop=True)\n",
    "#     playlist_data_full = pd.DataFrame(playlist_data)\n",
    "\n",
    "#     # Get timbre data\n",
    "\n",
    "#     timbre = pd.DataFrame(columns = ['song_timbre', 'song_timbre_start', 'song_timbre_end', 'loudness_start', 'loudness_end'])\n",
    "\n",
    "#     for track in track_ids:\n",
    "#         print('Getting timbre for: '+ track)\n",
    "#         track_timbre = get_timbre(track, playlist_data_full)\n",
    "#         timbre = pd.concat([timbre, track_timbre], axis=0)\n",
    "\n",
    "#     timbre = timbre.reset_index(drop=True)\n",
    "#     playlist_data = pd.concat([playlist_data, timbre], axis=1)\n",
    "\n",
    "#     playlist_data.to_csv('./data/test_set/playlist_data_' + str(x) + '.csv')\n",
    "#     playlist_data_full.to_csv('./data/test_set/playlist_data_full_' + str(x) + '.csv')\n",
    "#     x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get permissions to rearrange\n",
    "# from spotipy.oauth2 import SpotifyOAuth\n",
    "# scope = \"playlist-modify-public\"\n",
    "# sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope,redirect_uri='http://localhost:5678/',client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET))\n",
    "\n",
    "# # rearrange\n",
    "# sorted_ids = list(playlist_data_full['id'])\n",
    "\n",
    "# UPDATED_PLAYLIST = sp.playlist_replace_items(playlist_id,sorted_ids)\n",
    "# UPDATED_PLAYLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute all tracks: Random\n",
    "\n",
    "x = 1\n",
    "sorted_evals_baseline = []\n",
    "original_evals_baseline = []\n",
    "mean_squared_errors = []\n",
    "eval_changes_baseline = []\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    \n",
    "    # print('Running playlist ' + playlist_id)\n",
    "\n",
    "    # Read and set up data\n",
    "    playlist_data = pd.read_csv('./data/test_set/playlist_data_' + random_y + str(x) + '.csv')\n",
    "    playlist_data.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    playlist_data_full = playlist_data.copy(deep=True)\n",
    "    x += 1\n",
    "\n",
    "    # Remove unnecessary testing columns\n",
    "    playlist_data.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
    "\n",
    "    # Evaluate original order\n",
    "    original_order_eval = evaluate_data(playlist_data_full)\n",
    "    original_evals_baseline.append(original_order_eval)\n",
    "\n",
    "    # Randomise order\n",
    "    order = np.arange(len(playlist_data))\n",
    "    np.random.shuffle(order)\n",
    "    playlist_data_full['order'] = order\n",
    "    playlist_data_full = playlist_data_full.sort_values(by=['order'])\n",
    "    playlist_data_full['order'] = np.arange(1, playlist_data_full.shape[0]+1) # convert order to integer playlist track number\n",
    "\n",
    "    # Evaluate new order\n",
    "    sorted_order_eval = evaluate_data(playlist_data_full)\n",
    "    sorted_evals_baseline.append(sorted_order_eval)\n",
    "\n",
    "    y_true = playlist_data_full['track_number']\n",
    "    y_pred = playlist_data_full['order']\n",
    "    mean_squared_errors.append(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    track_eval_changes_baseline = []\n",
    "    \n",
    "    for metric in range(len(original_order_eval)):\n",
    "        track_eval_changes_baseline.append(sorted_order_eval[metric] - original_order_eval[metric])\n",
    "        \n",
    "    eval_changes_baseline.append(track_eval_changes_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_evals_baseline_df = pd.DataFrame.from_records(original_evals_baseline, columns=evaluation_vector_titles)\n",
    "sorted_evals_baseline_df = pd.DataFrame.from_records(sorted_evals_baseline, columns=evaluation_vector_titles)\n",
    "eval_changes_baseline_df = pd.DataFrame.from_records(eval_changes_baseline, columns=evaluation_vector_titles)\n",
    "\n",
    "trackNumTransitionOriginalMean_baseline = original_evals_baseline_df['trackNumTransition'].mean()\n",
    "trackNumTransitionSortedMean_baseline = sorted_evals_baseline_df['trackNumTransition'].mean()\n",
    "trackNumTransitionMeanChange_baseline = eval_changes_baseline_df['trackNumTransition'].mean()\n",
    "\n",
    "original_evals_baseline_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "original_evals_baseline_df['trackTotal'] = original_evals_baseline_df.mean(numeric_only=True, axis=1)\n",
    "original_evals_baseline_df.loc['metricTotalAlbumOriginal'] = original_evals_baseline_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionOriginalMean_baseline = original_evals_baseline_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "sorted_evals_baseline_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "sorted_evals_baseline_df['trackTotal'] = sorted_evals_baseline_df.mean(numeric_only=True, axis=1)\n",
    "sorted_evals_baseline_df.loc['metricTotalAlbumOriginal'] = sorted_evals_baseline_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionSortedMean_baseline = sorted_evals_baseline_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "eval_changes_baseline_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "eval_changes_baseline_df['trackTotal'] = eval_changes_baseline_df.mean(numeric_only=True, axis=1)\n",
    "eval_changes_baseline_df.loc['metricTotalAlbumOriginal'] = eval_changes_baseline_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionMeanChange_baseline = eval_changes_baseline_df.loc['metricTotalAlbumOriginal','trackTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute all tracks: ExtraTrees\n",
    "\n",
    "x = 1\n",
    "sorted_evals = []\n",
    "original_evals = []\n",
    "mean_squared_errors = []\n",
    "eval_changes = []\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    \n",
    "    # print('Running playlist ' + playlist_id)\n",
    "\n",
    "    # Read and set up data\n",
    "    playlist_data = pd.read_csv('./data/test_set/playlist_data_' + random_y + str(x) + '.csv')\n",
    "    playlist_data.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    playlist_data_full = playlist_data.copy(deep=True)\n",
    "    x += 1\n",
    "\n",
    "    # Remove unnecessary testing columns\n",
    "    playlist_data.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
    "\n",
    "    # Evaluate original order\n",
    "    original_order_eval = evaluate_data(playlist_data_full)\n",
    "    original_evals.append(original_order_eval)\n",
    "\n",
    "    # Load and run trained model\n",
    "    model = pickle.load(open('./regression/random_forest.sav', 'rb')) # change to whichever model we want to use\n",
    "    playlist_data_full['order'] = model.predict(playlist_data.values)\n",
    "    playlist_data_full = playlist_data_full.sort_values(by=['order'])\n",
    "    playlist_data_full['order'] = np.arange(1, playlist_data_full.shape[0]+1) # convert order to integer playlist track number\n",
    "\n",
    "    # Evaluate new order\n",
    "    sorted_order_eval = evaluate_data(playlist_data_full)\n",
    "    sorted_evals.append(sorted_order_eval)\n",
    "\n",
    "    y_true = playlist_data_full['track_number']\n",
    "    y_pred = playlist_data_full['order']\n",
    "    mean_squared_errors.append(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    track_eval_changes = []\n",
    "    \n",
    "    for metric in range(len(original_order_eval)):\n",
    "        track_eval_changes.append(sorted_order_eval[metric] - original_order_eval[metric])\n",
    "        \n",
    "    eval_changes.append(track_eval_changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_evals_df = pd.DataFrame.from_records(original_evals, columns=evaluation_vector_titles)\n",
    "sorted_evals_df = pd.DataFrame.from_records(sorted_evals, columns=evaluation_vector_titles)\n",
    "eval_changes_df = pd.DataFrame.from_records(eval_changes, columns=evaluation_vector_titles)\n",
    "\n",
    "trackNumTransitionOriginalMean = original_evals_df['trackNumTransition'].mean()\n",
    "trackNumTransitionSortedMean = sorted_evals_df['trackNumTransition'].mean()\n",
    "trackNumTransitionMeanChange = eval_changes_df['trackNumTransition'].mean()\n",
    "\n",
    "original_evals_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "original_evals_df['trackTotal'] = original_evals_df.mean(numeric_only=True, axis=1)\n",
    "original_evals_df.loc['metricTotalAlbumOriginal'] = original_evals_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionOriginalMean = original_evals_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "sorted_evals_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "sorted_evals_df['trackTotal'] = sorted_evals_df.mean(numeric_only=True, axis=1)\n",
    "sorted_evals_df.loc['metricTotalAlbumOriginal'] = sorted_evals_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionSortedMean = sorted_evals_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "eval_changes_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "eval_changes_df['trackTotal'] = eval_changes_df.mean(numeric_only=True, axis=1)\n",
    "eval_changes_df.loc['metricTotalAlbumOriginal'] = eval_changes_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionMeanChange = eval_changes_df.loc['metricTotalAlbumOriginal','trackTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evalute all tracks: ExtraTrees with Autoencoder\n",
    "\n",
    "encoder = tf.keras.models.load_model('./regression/encoder.h5')\n",
    "\n",
    "x = 1\n",
    "sorted_evals_auto = []\n",
    "original_evals_auto = []\n",
    "mean_squared_errors_auto = []\n",
    "eval_changes_auto = []\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    \n",
    "    # print('Running playlist ' + playlist_id)\n",
    "\n",
    "    # Read and set up data\n",
    "    playlist_data = pd.read_csv('./data/test_set/playlist_data_' + random_y + str(x) + '.csv')\n",
    "    playlist_data.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    playlist_data_full = playlist_data.copy(deep=True)\n",
    "    x += 1\n",
    "\n",
    "    # Remove unnecessary testing columns\n",
    "    playlist_data.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
    "\n",
    "    # Evaluate original order\n",
    "    original_order_eval = evaluate_data(playlist_data_full)\n",
    "    original_evals_auto.append(original_order_eval)\n",
    "\n",
    "    # Load and run trained model\n",
    "    encoded_playlist_data = encoder.predict(playlist_data)\n",
    "    model = pickle.load(open('./regression/autoencoder_random_forest.sav', 'rb')) # change to whichever model we want to use\n",
    "    playlist_data_full['order'] = model.predict(encoded_playlist_data)\n",
    "    playlist_data_full = playlist_data_full.sort_values(by=['order'])\n",
    "    playlist_data_full['order'] = np.arange(1, playlist_data_full.shape[0]+1) # convert order to integer playlist track number\n",
    "\n",
    "    # Evaluate new order\n",
    "    sorted_order_eval = evaluate_data(playlist_data_full)\n",
    "    sorted_evals_auto.append(sorted_order_eval)\n",
    "\n",
    "    y_true = playlist_data_full['track_number']\n",
    "    y_pred = playlist_data_full['order']\n",
    "    mean_squared_errors_auto.append(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    track_eval_changes_auto = []\n",
    "    \n",
    "    for metric in range(len(original_order_eval)):\n",
    "        track_eval_changes_auto.append(sorted_order_eval[metric] - original_order_eval[metric])\n",
    "        \n",
    "    eval_changes_auto.append(track_eval_changes_auto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_evals_auto_df = pd.DataFrame.from_records(original_evals_auto, columns=evaluation_vector_titles)\n",
    "sorted_evals_auto_df = pd.DataFrame.from_records(sorted_evals_auto, columns=evaluation_vector_titles)\n",
    "eval_changes_auto_df = pd.DataFrame.from_records(eval_changes_auto, columns=evaluation_vector_titles)\n",
    "\n",
    "trackNumTransitionOriginalMean_auto = original_evals_auto_df['trackNumTransition'].mean()\n",
    "trackNumTransitionSortedMean_auto = sorted_evals_auto_df['trackNumTransition'].mean()\n",
    "trackNumTransitionMeanChange_auto = eval_changes_auto_df['trackNumTransition'].mean()\n",
    "\n",
    "original_evals_auto_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "original_evals_auto_df['trackTotal'] = original_evals_auto_df.mean(numeric_only=True, axis=1)\n",
    "original_evals_auto_df.loc['metricTotalAlbumOriginal'] = original_evals_auto_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionOriginalMean_auto = original_evals_auto_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "sorted_evals_auto_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "sorted_evals_auto_df['trackTotal'] = sorted_evals_auto_df.mean(numeric_only=True, axis=1)\n",
    "sorted_evals_auto_df.loc['metricTotalAlbumOriginal'] = sorted_evals_auto_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionSortedMean_auto = sorted_evals_auto_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "eval_changes_auto_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "eval_changes_auto_df['trackTotal'] = eval_changes_auto_df.mean(numeric_only=True, axis=1)\n",
    "eval_changes_auto_df.loc['metricTotalAlbumOriginal'] = eval_changes_auto_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionMeanChange_auto = eval_changes_auto_df.loc['metricTotalAlbumOriginal','trackTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evalute all tracks: ExtraTrees Predict Next with unoptimised search\n",
    "\n",
    "x = 1\n",
    "sorted_evals_next = []\n",
    "original_evals_next = []\n",
    "mean_squared_errors = []\n",
    "eval_changes_next = []\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    \n",
    "    # print('Running playlist ' + playlist_id)\n",
    "\n",
    "    # Read and set up data\n",
    "    playlist_data = pd.read_csv('./data/test_set/playlist_data_' + random_y + str(x) + '.csv')\n",
    "    playlist_data.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    playlist_data_full = playlist_data.copy(deep=True)\n",
    "    playlist_data.loc[:,['loudness', 'tempo', 'loudness_start', 'loudness_end']] = MinMaxScaler().fit_transform(playlist_data.loc[:,['loudness', 'tempo', 'loudness_start', 'loudness_end']])\n",
    "    x += 1\n",
    "\n",
    "    # Remove unnecessary testing columns\n",
    "    playlist_data.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
    "\n",
    "    # Evaluate original order\n",
    "    original_order_eval = evaluate_data(playlist_data_full)\n",
    "    original_evals_next.append(original_order_eval)\n",
    "\n",
    "    # Load and run trained model\n",
    "    model = pickle.load(open('./regression/rf_predict_next.sav', 'rb')) # change to whichever model we want to use\n",
    "    optimal_songs = model.predict(playlist_data.values)\n",
    "    \n",
    "    # Order songs based on optimal result\n",
    "    sorted_order = [0]\n",
    "    for current_track in range(playlist_data.shape[0]-1):\n",
    "        distances = []\n",
    "        for other_track in range(playlist_data.shape[0]):\n",
    "            # print(other_track)\n",
    "            if current_track != other_track:\n",
    "                distances.append(np.linalg.norm(optimal_songs[current_track]-playlist_data.iloc[other_track]))\n",
    "            else:\n",
    "                distances.append(1)\n",
    "        distances_temp = distances.copy()\n",
    "        # print('D ' + str(distances))\n",
    "        for other_track in range(len(distances)):\n",
    "            # print('OT ' + str(other_track))\n",
    "            # print('D_Temp ' + str(distances_temp))\n",
    "            if distances.index(min(distances_temp)) not in sorted_order:\n",
    "                # print('SO ' + str(distances.index(min(distances_temp))))\n",
    "                sorted_order.append(distances.index(min(distances_temp)))\n",
    "                break\n",
    "            else:\n",
    "                # print('Removed ' + str(min(distances_temp)))\n",
    "                distances_temp.remove(min(distances_temp))\n",
    "        # print(str(other_track) + ' ' + str(distances))\n",
    "        # print('end' + str(distances))\n",
    "        # sorted()\n",
    "\n",
    "    playlist_data_full['order'] = sorted_order\n",
    "    playlist_data_full = playlist_data_full.sort_values(by=['order'])\n",
    "    playlist_data_full['order'] = np.arange(1, playlist_data_full.shape[0]+1) # convert order to integer playlist track number\n",
    "        \n",
    "    # Evaluate new order\n",
    "    sorted_order_eval = evaluate_data(playlist_data_full)\n",
    "    sorted_evals_next.append(sorted_order_eval)\n",
    "\n",
    "    # y_true = playlist_data_full['track_number']\n",
    "    # y_pred = playlist_data_full['order']\n",
    "    # mean_squared_errors_random.append(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    track_eval_changes = []\n",
    "\n",
    "    for metric in range(len(original_order_eval)):\n",
    "        track_eval_changes.append(sorted_order_eval[metric] - original_order_eval[metric])\n",
    "        \n",
    "    eval_changes_next.append(track_eval_changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_evals_next_df = pd.DataFrame.from_records(original_evals_next, columns=evaluation_vector_titles)\n",
    "sorted_evals_next_df = pd.DataFrame.from_records(sorted_evals_next, columns=evaluation_vector_titles)\n",
    "eval_changes_next_df = pd.DataFrame.from_records(eval_changes_next, columns=evaluation_vector_titles)\n",
    "\n",
    "trackNumTransitionOriginalMean_next = original_evals_next_df['trackNumTransition'].mean()\n",
    "trackNumTransitionSortedMean_next = sorted_evals_next_df['trackNumTransition'].mean()\n",
    "trackNumTransitionMeanChange_next = eval_changes_next_df['trackNumTransition'].mean()\n",
    "\n",
    "original_evals_next_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "original_evals_next_df['trackTotal'] = original_evals_next_df.mean(numeric_only=True, axis=1)\n",
    "original_evals_next_df.loc['metricTotalAlbumOriginal'] = original_evals_next_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionOriginalMean_next = original_evals_next_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "sorted_evals_next_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "sorted_evals_next_df['trackTotal'] = sorted_evals_next_df.mean(numeric_only=True, axis=1)\n",
    "sorted_evals_next_df.loc['metricTotalAlbumOriginal'] = sorted_evals_next_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionSortedMean_next = sorted_evals_next_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "eval_changes_next_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "eval_changes_next_df['trackTotal'] = eval_changes_next_df.mean(numeric_only=True, axis=1)\n",
    "eval_changes_next_df.loc['metricTotalAlbumOriginal'] = eval_changes_next_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionMeanChange_next = eval_changes_next_df.loc['metricTotalAlbumOriginal','trackTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreeRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mark\\.conda\\envs\\cuda-11-2\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ExtraTreesRegressor from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evalute all tracks: ExtraTrees Predict Next with Optimised Search\n",
    "\n",
    "x = 1\n",
    "sorted_evals_search = []\n",
    "original_evals_search = []\n",
    "mean_squared_errors = []\n",
    "eval_changes_search = []\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    \n",
    "    # print('Running playlist ' + playlist_id)\n",
    "\n",
    "    # Read and set up data\n",
    "    playlist_data = pd.read_csv('./data/test_set/playlist_data_' + random_y + str(x) + '.csv')\n",
    "    playlist_data.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    # playlist_data.drop(index = [6, 7, 8, 9, 10, 11], axis = 0, inplace = True)\n",
    "    playlist_data_full = playlist_data.copy(deep=True)\n",
    "    playlist_data.loc[:,['loudness', 'tempo', 'loudness_start', 'loudness_end']] = MinMaxScaler().fit_transform(playlist_data.loc[:,['loudness', 'tempo', 'loudness_start', 'loudness_end']])\n",
    "    x += 1\n",
    "\n",
    "    # Remove unnecessary testing columns\n",
    "    playlist_data.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
    "\n",
    "    # Evaluate original order\n",
    "    original_order_eval = evaluate_data(playlist_data_full)\n",
    "    original_evals_search.append(original_order_eval)\n",
    "\n",
    "    # Load and run trained model\n",
    "    model = pickle.load(open('./regression/rf_predict_next.sav', 'rb')) # change to whichever model we want to use\n",
    "    optimal_songs = model.predict(playlist_data.values)\n",
    "    \n",
    "    # Get all distances between all songs\n",
    "    all_distances = []\n",
    "    for current_track in range(playlist_data.shape[0]):\n",
    "        distances = []\n",
    "        for other_track in range(playlist_data.shape[0]):\n",
    "            # print(other_track)\n",
    "            if current_track != other_track:\n",
    "                distances.append(np.linalg.norm(optimal_songs[current_track]-playlist_data.iloc[other_track]))\n",
    "            else:\n",
    "                distances.append(0)\n",
    "        all_distances.append(distances)\n",
    "\n",
    "    \n",
    "    transitions = [0] * len(all_distances)\n",
    "    order = [0] * len(all_distances)\n",
    "    sorted_order = [0] * len(all_distances)\n",
    "    columnHeaderNums = np.arange(start=0, stop=len(all_distances), step=1)    \n",
    "    all_distances_df = pd.DataFrame.from_records(all_distances, columns = columnHeaderNums)\n",
    "    \n",
    "    for i in columnHeaderNums:\n",
    "        # Find worst cell\n",
    "        maxValue = all_distances_df.max().max()\n",
    "        # select transition A->B (row->column)\n",
    "        for searchx in range(0,len(all_distances_df)):\n",
    "            for searchy in range(0,len(all_distances_df)):\n",
    "                if all_distances_df.iloc[searchx,searchy] == maxValue:\n",
    "                    indexX = list(all_distances_df.index.values)[searchx]\n",
    "                    indexY = list(all_distances_df.columns)[searchy]\n",
    "                    # print (indexX,indexY)\n",
    "                    if i == 0:\n",
    "                        indexYMax = indexY\n",
    "        # remove column of transitioned from (A)\n",
    "        all_distances_df.drop(columns = indexY, axis = 1, inplace = True)\n",
    "        # remove row of transitioned to (B)\n",
    "        all_distances_df.drop(index = indexX, axis = 0, inplace = True)\n",
    "        # Save transition\n",
    "        transitions[indexX] = indexY\n",
    "\n",
    "    for i in range(0,len(columnHeaderNums)-1):\n",
    "        if i == 0:\n",
    "            order[i] = indexYMax\n",
    "        else:\n",
    "            order[i+1] = transitions[order[i]]\n",
    "    \n",
    "    for i in range(0,len(columnHeaderNums)):\n",
    "        sorted_order[order[i]] = i\n",
    "\n",
    "    # sorted_order = [0]\n",
    "    # current_track = 0\n",
    "    # flag = False\n",
    "    # while current_track < playlist_data.shape[0]:\n",
    "    #     if flag == False:\n",
    "    #         current_track_distances = all_distances[current_track].copy()\n",
    "    #     if len(current_track_distances) == 0:\n",
    "    #         break\n",
    "    #     worst_transition = max(current_track_distances)\n",
    "    #     while worst_transition > 4:\n",
    "    #         current_track_distances.remove(worst_transition)\n",
    "    #         worst_transition = max(current_track_distances)\n",
    "    #     if all_distances[current_track].index(worst_transition) not in sorted_order:\n",
    "    #         sorted_order.append(all_distances[current_track].index(worst_transition))\n",
    "    #         flag = False\n",
    "    #     else:\n",
    "    #         flag = True\n",
    "    #         current_track_distances.remove(worst_transition)\n",
    "    #         current_track -= 1\n",
    "    #     current_track += 1\n",
    "\n",
    "    # print(sorted_order)\n",
    "    \n",
    "    # # UCS to find shortest distance through album\n",
    "    # frontier = []\n",
    "    # explored = []\n",
    "    # path_costs = []\n",
    "    # depth = 0\n",
    "\n",
    "    # for i in range(1, len(all_distances[0])):\n",
    "    #     frontier.append([0, all_distances[0].index(all_distances[0][i])])\n",
    "    #     path_costs.append(all_distances[0][i])\n",
    "    # depth += 1\n",
    "\n",
    "    # # Explore\n",
    "    # while frontier != []:\n",
    "    # # while min(path_costs) < 1000:\n",
    "    # # while min(path_costs) < len(all_distances) * 10:\n",
    "    #     lowest_cost_node = frontier[path_costs.index(min(path_costs))]\n",
    "    #     lowest_cost_node = [x for x in lowest_cost_node if math.isnan(x) == False]\n",
    "    #     print(lowest_cost_node, min(path_costs))\n",
    "    #     depth = len(lowest_cost_node) + 1\n",
    "    #     explored.append(lowest_cost_node)\n",
    "    #     frontier.remove(lowest_cost_node)\n",
    "    #     path_costs.remove(min(path_costs))\n",
    "    #     if depth < len(all_distances):\n",
    "    #         for i in range(len(all_distances[depth])):\n",
    "    #             if all_distances[depth].index(all_distances[depth][i]) not in lowest_cost_node:\n",
    "    #                 if depth < len(all_distances) - 2:\n",
    "    #                     if all_distances[depth][i] < 1: # If the distance > 1, it's probably not the right path?\n",
    "    #                         next_node = lowest_cost_node.copy()\n",
    "    #                         next_node.append(all_distances[depth].index(all_distances[depth][i]))\n",
    "    #                         frontier.append(next_node)\n",
    "    #                         path_costs.append(min(path_costs) + all_distances[depth][i])\n",
    "    #                 else:\n",
    "    #                     next_node = lowest_cost_node.copy()\n",
    "    #                     next_node.append(all_distances[depth].index(all_distances[depth][i]))\n",
    "    #                     frontier.append(next_node)\n",
    "    #                     path_costs.append(min(path_costs) + all_distances[depth][i])\n",
    "\n",
    "    # sorted_order = lowest_cost_node\n",
    "\n",
    "    playlist_data_full['order'] = sorted_order\n",
    "    playlist_data_full = playlist_data_full.sort_values(by=['order'])\n",
    "    playlist_data_full['order'] = np.arange(1, playlist_data_full.shape[0]+1) # convert order to integer playlist track number\n",
    "        \n",
    "    # Evaluate new order\n",
    "    sorted_order_eval = evaluate_data(playlist_data_full)\n",
    "    sorted_evals_search.append(sorted_order_eval)\n",
    "\n",
    "    # y_true = playlist_data_full['track_number']\n",
    "    # y_pred = playlist_data_full['order']\n",
    "    # mean_squared_errors_random.append(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    track_eval_changes = []\n",
    "\n",
    "    for metric in range(len(original_order_eval)):\n",
    "        track_eval_changes.append(sorted_order_eval[metric] - original_order_eval[metric])\n",
    "        \n",
    "    eval_changes_search.append(track_eval_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_evals_search_df = pd.DataFrame.from_records(original_evals_search, columns=evaluation_vector_titles)\n",
    "sorted_evals_search_df = pd.DataFrame.from_records(sorted_evals_search, columns=evaluation_vector_titles)\n",
    "eval_changes_search_df = pd.DataFrame.from_records(eval_changes_search, columns=evaluation_vector_titles)\n",
    "\n",
    "trackNumTransitionOriginalMean_search = original_evals_search_df['trackNumTransition'].mean()\n",
    "trackNumTransitionSortedMean_search = sorted_evals_search_df['trackNumTransition'].mean()\n",
    "trackNumTransitionMeanChange_search = eval_changes_search_df['trackNumTransition'].mean()\n",
    "\n",
    "original_evals_search_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "original_evals_search_df['trackTotal'] = original_evals_search_df.mean(numeric_only=True, axis=1)\n",
    "original_evals_search_df.loc['metricTotalAlbumOriginal'] = original_evals_search_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionOriginalMean_search = original_evals_search_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "sorted_evals_search_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "sorted_evals_search_df['trackTotal'] = sorted_evals_search_df.mean(numeric_only=True, axis=1)\n",
    "sorted_evals_search_df.loc['metricTotalAlbumOriginal'] = sorted_evals_search_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionSortedMean_search = sorted_evals_search_df.loc['metricTotalAlbumOriginal','trackTotal']\n",
    "\n",
    "eval_changes_search_df.drop(columns = ['trackNumTransition', 'loudnessTransition'], axis = 1, inplace = True)\n",
    "eval_changes_search_df['trackTotal'] = eval_changes_search_df.mean(numeric_only=True, axis=1)\n",
    "eval_changes_search_df.loc['metricTotalAlbumOriginal'] = eval_changes_search_df.mean(numeric_only=True, axis=0)\n",
    "featureTransitionMeanChange_search = eval_changes_search_df.loc['metricTotalAlbumOriginal','trackTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Sequential Tracks</th>\n",
       "      <th>% Good Feature Changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Order</th>\n",
       "      <td>0.102684</td>\n",
       "      <td>0.261182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline (Random)</th>\n",
       "      <td>0.099013</td>\n",
       "      <td>0.237797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.125793</td>\n",
       "      <td>0.246644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees Predict Next</th>\n",
       "      <td>0.095343</td>\n",
       "      <td>0.241373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees Predict Next Optimised</th>\n",
       "      <td>0.070472</td>\n",
       "      <td>0.250150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees Autoencoder</th>\n",
       "      <td>0.114547</td>\n",
       "      <td>0.276815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   % Sequential Tracks  % Good Feature Changes\n",
       "Original Order                                0.102684                0.261182\n",
       "Baseline (Random)                             0.099013                0.237797\n",
       "ExtraTrees                                    0.125793                0.246644\n",
       "ExtraTrees Predict Next                       0.095343                0.241373\n",
       "ExtraTrees Predict Next Optimised             0.070472                0.250150\n",
       "ExtraTrees Autoencoder                        0.114547                0.276815"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_df = pd.DataFrame(np.array([\n",
    "    [trackNumTransitionOriginalMean, featureTransitionOriginalMean],\n",
    "    [trackNumTransitionSortedMean_baseline, featureTransitionSortedMean_baseline],\n",
    "    [trackNumTransitionSortedMean, featureTransitionSortedMean],\n",
    "    [trackNumTransitionSortedMean_next, featureTransitionSortedMean_next],\n",
    "    [trackNumTransitionSortedMean_search, featureTransitionSortedMean_search],\n",
    "    [trackNumTransitionSortedMean_auto, featureTransitionSortedMean_auto]\n",
    "    ]),\n",
    "    columns=['% Sequential Tracks', '% Good Feature Changes'],\n",
    "    index=['Original Order',\n",
    "    'Baseline (Random)',\n",
    "    'ExtraTrees',\n",
    "    'ExtraTrees Predict Next',\n",
    "    'ExtraTrees Predict Next Optimised',\n",
    "    'ExtraTrees Autoencoder'\n",
    "    ])\n",
    "\n",
    "evals_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
