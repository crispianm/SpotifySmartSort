{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crispianm/MDM3-UKCRIC/blob/main/TestingDNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gifiwVRpyh-g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import os \n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "613JO7erysnn",
        "outputId": "d4f5797c-100d-4265-dbf9-2db9c6782ac4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>time_signature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.788</td>\n",
              "      <td>0.616</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0337</td>\n",
              "      <td>0.00286</td>\n",
              "      <td>0.549000</td>\n",
              "      <td>0.0952</td>\n",
              "      <td>0.6960</td>\n",
              "      <td>119.037</td>\n",
              "      <td>275387</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.712</td>\n",
              "      <td>0.500</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.82500</td>\n",
              "      <td>0.314000</td>\n",
              "      <td>0.1060</td>\n",
              "      <td>0.6820</td>\n",
              "      <td>90.039</td>\n",
              "      <td>322147</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.740</td>\n",
              "      <td>0.682</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0504</td>\n",
              "      <td>0.06920</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.3810</td>\n",
              "      <td>0.4100</td>\n",
              "      <td>113.201</td>\n",
              "      <td>544627</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.702</td>\n",
              "      <td>0.297</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0317</td>\n",
              "      <td>0.89400</td>\n",
              "      <td>0.485000</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.0676</td>\n",
              "      <td>110.116</td>\n",
              "      <td>228507</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.775</td>\n",
              "      <td>0.585</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0271</td>\n",
              "      <td>0.04220</td>\n",
              "      <td>0.619000</td>\n",
              "      <td>0.0770</td>\n",
              "      <td>0.5180</td>\n",
              "      <td>109.942</td>\n",
              "      <td>337560</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4971</th>\n",
              "      <td>0.530</td>\n",
              "      <td>0.275</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0349</td>\n",
              "      <td>0.46000</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.0729</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>133.973</td>\n",
              "      <td>271907</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4972</th>\n",
              "      <td>0.490</td>\n",
              "      <td>0.495</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>0.2300</td>\n",
              "      <td>148.967</td>\n",
              "      <td>263667</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4973</th>\n",
              "      <td>0.767</td>\n",
              "      <td>0.355</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0445</td>\n",
              "      <td>0.14600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2980</td>\n",
              "      <td>0.2880</td>\n",
              "      <td>119.992</td>\n",
              "      <td>161893</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>0.743</td>\n",
              "      <td>0.379</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0784</td>\n",
              "      <td>0.20700</td>\n",
              "      <td>0.196000</td>\n",
              "      <td>0.1110</td>\n",
              "      <td>0.1830</td>\n",
              "      <td>127.030</td>\n",
              "      <td>412942</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>0.780</td>\n",
              "      <td>0.819</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0321</td>\n",
              "      <td>0.18300</td>\n",
              "      <td>0.859000</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>0.9610</td>\n",
              "      <td>109.989</td>\n",
              "      <td>420263</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4976 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      danceability  energy  key  mode  speechiness  acousticness  \\\n",
              "0            0.788   0.616    9     0       0.0337       0.00286   \n",
              "1            0.712   0.500    9     0       0.0338       0.82500   \n",
              "2            0.740   0.682    9     0       0.0504       0.06920   \n",
              "3            0.702   0.297   10     0       0.0317       0.89400   \n",
              "4            0.775   0.585   10     0       0.0271       0.04220   \n",
              "...            ...     ...  ...   ...          ...           ...   \n",
              "4971         0.530   0.275    2     0       0.0349       0.46000   \n",
              "4972         0.490   0.495    4     0       0.0338       0.17300   \n",
              "4973         0.767   0.355   11     1       0.0445       0.14600   \n",
              "4974         0.743   0.379    1     1       0.0784       0.20700   \n",
              "4975         0.780   0.819    5     1       0.0321       0.18300   \n",
              "\n",
              "      instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
              "0             0.549000    0.0952   0.6960  119.037       275387   \n",
              "1             0.314000    0.1060   0.6820   90.039       322147   \n",
              "2             0.530000    0.3810   0.4100  113.201       544627   \n",
              "3             0.485000    0.1030   0.0676  110.116       228507   \n",
              "4             0.619000    0.0770   0.5180  109.942       337560   \n",
              "...                ...       ...      ...      ...          ...   \n",
              "4971          0.000011    0.0729   0.0698  133.973       271907   \n",
              "4972          0.000000    0.0794   0.2300  148.967       263667   \n",
              "4973          0.000000    0.2980   0.2880  119.992       161893   \n",
              "4974          0.196000    0.1110   0.1830  127.030       412942   \n",
              "4975          0.859000    0.0790   0.9610  109.989       420263   \n",
              "\n",
              "      time_signature  \n",
              "0                  4  \n",
              "1                  4  \n",
              "2                  4  \n",
              "3                  4  \n",
              "4                  4  \n",
              "...              ...  \n",
              "4971               4  \n",
              "4972               4  \n",
              "4973               4  \n",
              "4974               4  \n",
              "4975               4  \n",
              "\n",
              "[4976 rows x 12 columns]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#file = open('SingleSidedAmplitudeSpectrum_labelled.csv')\n",
        "#file = open('LabelledMatrixTimeDomain.csv')\n",
        "\n",
        "data = pd.read_csv(\"./data/data.csv\")\n",
        "\n",
        "# data['binary_order'] = data['track_number']%10\n",
        "order = data['track_number']/data['total_tracks']\n",
        "\n",
        "\n",
        "labels = order #data['binary_order']\n",
        "\n",
        "columns_to_remove = ['Unnamed: 0',\n",
        "                    'id',\n",
        "                    'track_title',\n",
        "                    'album_title',\n",
        "                    'album_artist',\n",
        "                    'track_number',\n",
        "                    'total_tracks',\n",
        "                    'order',\n",
        "                    'loudness',\n",
        "                    'binary_order']\n",
        "\n",
        "data.drop(columns = columns_to_remove, axis = 1, inplace = True)\n",
        "\n",
        "data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_set, test_set, training_labels, test_labels = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "num_classes = len(np.unique(training_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY_9CBuz2QB6",
        "outputId": "4a007a53-8491-44d8-d0ba-94da95d5ca27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "training_labels_categorical = to_categorical(training_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)\n",
        "print(training_labels_categorical[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nyPiSIJu3EiL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "117/117 [==============================] - 3s 5ms/step - loss: 2091.3892 - accuracy: 0.0943\n",
            "Epoch 2/20\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 398.1813 - accuracy: 0.0997\n",
            "Epoch 3/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 302.3837 - accuracy: 0.0975\n",
            "Epoch 4/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 254.9072 - accuracy: 0.0954\n",
            "Epoch 5/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 206.8293 - accuracy: 0.1021: 0s - loss: 195.7693 - accuracy: 0.09\n",
            "Epoch 6/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 178.2129 - accuracy: 0.0908\n",
            "Epoch 7/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 133.8188 - accuracy: 0.1010\n",
            "Epoch 8/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 192.4620 - accuracy: 0.1024\n",
            "Epoch 9/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 134.5491 - accuracy: 0.1018\n",
            "Epoch 10/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 79.6555 - accuracy: 0.1069\n",
            "Epoch 11/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 76.4631 - accuracy: 0.0997\n",
            "Epoch 12/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 57.0379 - accuracy: 0.0997\n",
            "Epoch 13/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 51.3387 - accuracy: 0.1168\n",
            "Epoch 14/20\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 34.3793 - accuracy: 0.0978\n",
            "Epoch 15/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 12.0872 - accuracy: 0.1034\n",
            "Epoch 16/20\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.9687 - accuracy: 0.1152TA: 0s - loss: 10.3383 - accuracy:\n",
            "Epoch 17/20\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 5.0476 - accuracy: 0.1050\n",
            "Epoch 18/20\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.9902 - accuracy: 0.1034\n",
            "Epoch 19/20\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.9921 - accuracy: 0.1064\n",
            "Epoch 20/20\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 5.2843 - accuracy: 0.1107\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "num_features = training_set.shape[1]\n",
        "model.add(Dense(128, input_dim = num_features, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu', input_dim = num_features))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu', input_dim = num_features))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = 0.001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(training_set, training_labels_categorical, epochs=20) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQP3yNEY45yR",
        "outputId": "a851c3f2-cc67-4320-f4c2-2d299aa65c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39/39 [==============================] - 0s 3ms/step - loss: 6.7835 - accuracy: 0.1061\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_set, test_labels_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "tfWjeMHB5TjF",
        "outputId": "cb63c115-c080-4cd5-ec95-d8ec2ddfcf28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.values\n",
        "Y = labels.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3483, 12) (746, 12) (747, 12) (3483,) (746,) (747,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(12,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 6ms/step - loss: 0.6955 - accuracy: 0.0037 - val_loss: 0.6954 - val_accuracy: 0.0054\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 1s 6ms/step - loss: 0.6937 - accuracy: 0.0135 - val_loss: 0.6937 - val_accuracy: 0.0174\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.0215 - val_loss: 0.6934 - val_accuracy: 0.0214\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.0238 - val_loss: 0.6931 - val_accuracy: 0.0241\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0250 - val_loss: 0.6930 - val_accuracy: 0.0214\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.0281 - val_loss: 0.6932 - val_accuracy: 0.0214\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.0258 - val_loss: 0.6932 - val_accuracy: 0.0214\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6928 - accuracy: 0.0253 - val_loss: 0.6930 - val_accuracy: 0.0228\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.0301 - val_loss: 0.6931 - val_accuracy: 0.0201\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6926 - accuracy: 0.0264 - val_loss: 0.6927 - val_accuracy: 0.0268\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.0293 - val_loss: 0.6927 - val_accuracy: 0.0268\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.0273 - val_loss: 0.6925 - val_accuracy: 0.0295\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6924 - accuracy: 0.0310 - val_loss: 0.6926 - val_accuracy: 0.0282\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.0304 - val_loss: 0.6926 - val_accuracy: 0.0282\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.0310 - val_loss: 0.6927 - val_accuracy: 0.0282\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.0313 - val_loss: 0.6929 - val_accuracy: 0.0255\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.0278 - val_loss: 0.6925 - val_accuracy: 0.0295\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.0276 - val_loss: 0.6922 - val_accuracy: 0.0308\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.0310 - val_loss: 0.6921 - val_accuracy: 0.0322\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.0304 - val_loss: 0.6920 - val_accuracy: 0.0322\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=20,\n",
        "          validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.0321\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.03212851285934448"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, Y_test)[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 11ms/step - loss: -46826244.0000 - accuracy: 0.1324 - val_loss: -378064192.0000 - val_accuracy: 0.1381\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -9936221184.0000 - accuracy: 0.1329 - val_loss: -36709613568.0000 - val_accuracy: 0.1381\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -176697556992.0000 - accuracy: 0.1329 - val_loss: -434110791680.0000 - val_accuracy: 0.1381\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 1s 12ms/step - loss: -1212613918720.0000 - accuracy: 0.1329 - val_loss: -2319944515584.0000 - val_accuracy: 0.1381\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -4835137028096.0000 - accuracy: 0.1329 - val_loss: -7962307330048.0000 - val_accuracy: 0.1381\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -14043175714816.0000 - accuracy: 0.1329 - val_loss: -20994347499520.0000 - val_accuracy: 0.1381\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -33598367334400.0000 - accuracy: 0.1329 - val_loss: -46751830507520.0000 - val_accuracy: 0.1381\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -69754001817600.0000 - accuracy: 0.1329 - val_loss: -91976565260288.0000 - val_accuracy: 0.1381\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -129840300687360.0000 - accuracy: 0.1329 - val_loss: -165007711010816.0000 - val_accuracy: 0.1381\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -223298319286272.0000 - accuracy: 0.1329 - val_loss: -275389763026944.0000 - val_accuracy: 0.1381\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -361327377776640.0000 - accuracy: 0.1329 - val_loss: -434019867033600.0000 - val_accuracy: 0.1381\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 1s 6ms/step - loss: -556486094749696.0000 - accuracy: 0.1329 - val_loss: -652982064513024.0000 - val_accuracy: 0.1381\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: -822160423649280.0000 - accuracy: 0.1329 - val_loss: -948835249553408.0000 - val_accuracy: 0.1381\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: -1172412389392384.0000 - accuracy: 0.1329 - val_loss: -1334809666256896.0000 - val_accuracy: 0.1381\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: -1623608904384512.0000 - accuracy: 0.1329 - val_loss: -1825396131627008.0000 - val_accuracy: 0.1381\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: -2192963459350528.0000 - accuracy: 0.1329 - val_loss: -2441009497636864.0000 - val_accuracy: 0.1381\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: -2897544656977920.0000 - accuracy: 0.1329 - val_loss: -3190658458189824.0000 - val_accuracy: 0.1381\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: -3756443626897408.0000 - accuracy: 0.1329 - val_loss: -4098035797721088.0000 - val_accuracy: 0.1381\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 1s 7ms/step - loss: -4788737674313728.0000 - accuracy: 0.1329 - val_loss: -5192532782743552.0000 - val_accuracy: 0.1381\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -6018139313668096.0000 - accuracy: 0.1329 - val_loss: -6473121305460736.0000 - val_accuracy: 0.1381\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -7464268224004096.0000 - accuracy: 0.1329 - val_loss: -7972769803272192.0000 - val_accuracy: 0.1381\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -9143497894395904.0000 - accuracy: 0.1329 - val_loss: -9724230086164480.0000 - val_accuracy: 0.1381\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -11084449450033152.0000 - accuracy: 0.1329 - val_loss: -11735548238495744.0000 - val_accuracy: 0.1381\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -13307260381954048.0000 - accuracy: 0.1329 - val_loss: -14023713540276224.0000 - val_accuracy: 0.1381\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -15841773196673024.0000 - accuracy: 0.1329 - val_loss: -16619556340498432.0000 - val_accuracy: 0.1381\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -18706195334299648.0000 - accuracy: 0.1329 - val_loss: -19554580224278528.0000 - val_accuracy: 0.1381\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -21927083651366912.0000 - accuracy: 0.1329 - val_loss: -22845478655754240.0000 - val_accuracy: 0.1381\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -25527198253318144.0000 - accuracy: 0.1329 - val_loss: -26504608255836160.0000 - val_accuracy: 0.1381\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -29532203717230592.0000 - accuracy: 0.1329 - val_loss: -30608060812623872.0000 - val_accuracy: 0.1381\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -33971696662740992.0000 - accuracy: 0.1329 - val_loss: -35102080515440640.0000 - val_accuracy: 0.1381\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -38865403874639872.0000 - accuracy: 0.1329 - val_loss: -40057450572808192.0000 - val_accuracy: 0.1381\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -44252645778522112.0000 - accuracy: 0.1329 - val_loss: -45499698122850304.0000 - val_accuracy: 0.1381\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -50162752706052096.0000 - accuracy: 0.1329 - val_loss: -51469367656841216.0000 - val_accuracy: 0.1381\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -56614875916402688.0000 - accuracy: 0.1329 - val_loss: -57984429317947392.0000 - val_accuracy: 0.1381\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -63639127425286144.0000 - accuracy: 0.1329 - val_loss: -65042791457095680.0000 - val_accuracy: 0.1381\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -71281360303554560.0000 - accuracy: 0.1329 - val_loss: -72706984503148544.0000 - val_accuracy: 0.1381\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -79569019392229376.0000 - accuracy: 0.1329 - val_loss: -81016234392420352.0000 - val_accuracy: 0.1381\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -88519447769251840.0000 - accuracy: 0.1329 - val_loss: -90017120045236224.0000 - val_accuracy: 0.1381\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -98183837149822976.0000 - accuracy: 0.1329 - val_loss: -99716822646915072.0000 - val_accuracy: 0.1381\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -108581626555924480.0000 - accuracy: 0.1329 - val_loss: -110130374582992896.0000 - val_accuracy: 0.1381\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -119759330483372032.0000 - accuracy: 0.1329 - val_loss: -121258308429414400.0000 - val_accuracy: 0.1381\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -131716407766286336.0000 - accuracy: 0.1329 - val_loss: -133245046756474880.0000 - val_accuracy: 0.1381\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -144527676734963712.0000 - accuracy: 0.1329 - val_loss: -145969754954268672.0000 - val_accuracy: 0.1381\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -158189366408118272.0000 - accuracy: 0.1329 - val_loss: -159623267009691648.0000 - val_accuracy: 0.1381\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 1s 8ms/step - loss: -172752775875133440.0000 - accuracy: 0.1329 - val_loss: -174210659574087680.0000 - val_accuracy: 0.1381\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -188267881375465472.0000 - accuracy: 0.1329 - val_loss: -189529845846245376.0000 - val_accuracy: 0.1381\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -204751313022484480.0000 - accuracy: 0.1329 - val_loss: -205940400488185856.0000 - val_accuracy: 0.1381\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -222255228899033088.0000 - accuracy: 0.1329 - val_loss: -223424696954126336.0000 - val_accuracy: 0.1381\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -240828265214771200.0000 - accuracy: 0.1329 - val_loss: -241850141013704704.0000 - val_accuracy: 0.1381\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -260480712711340032.0000 - accuracy: 0.1329 - val_loss: -261334242972139520.0000 - val_accuracy: 0.1381\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -281276291523543040.0000 - accuracy: 0.1329 - val_loss: -282042548048887808.0000 - val_accuracy: 0.1381\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -303247677762568192.0000 - accuracy: 0.1329 - val_loss: -303826020878778368.0000 - val_accuracy: 0.1381\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -326452939386257408.0000 - accuracy: 0.1329 - val_loss: -326710293826633728.0000 - val_accuracy: 0.1381\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -350869072549773312.0000 - accuracy: 0.1329 - val_loss: -350995585106444288.0000 - val_accuracy: 0.1381\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -376638773246558208.0000 - accuracy: 0.1329 - val_loss: -376450103923179520.0000 - val_accuracy: 0.1381\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -403703767360339968.0000 - accuracy: 0.1329 - val_loss: -403272724442513408.0000 - val_accuracy: 0.1381\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -432156620026281984.0000 - accuracy: 0.1329 - val_loss: -431365212172451840.0000 - val_accuracy: 0.1381\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -462049351888273408.0000 - accuracy: 0.1329 - val_loss: -460958395835351040.0000 - val_accuracy: 0.1381\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -493462330374356992.0000 - accuracy: 0.1329 - val_loss: -491973419831656448.0000 - val_accuracy: 0.1381\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -526407409594269696.0000 - accuracy: 0.1329 - val_loss: -524504739082141696.0000 - val_accuracy: 0.1381\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -560894313353969664.0000 - accuracy: 0.1329 - val_loss: -558662923224875008.0000 - val_accuracy: 0.1381\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -597049176253005824.0000 - accuracy: 0.1329 - val_loss: -594268786224267264.0000 - val_accuracy: 0.1381\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -634834168219435008.0000 - accuracy: 0.1329 - val_loss: -631696024594808832.0000 - val_accuracy: 0.1381\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -674420297671114752.0000 - accuracy: 0.1329 - val_loss: -670543625830006784.0000 - val_accuracy: 0.1381\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -715776984440897536.0000 - accuracy: 0.1329 - val_loss: -711533213155065856.0000 - val_accuracy: 0.1381\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -758972741847089152.0000 - accuracy: 0.1329 - val_loss: -754259066779336704.0000 - val_accuracy: 0.1381\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -804095874417295360.0000 - accuracy: 0.1329 - val_loss: -798547807463014400.0000 - val_accuracy: 0.1381\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -851115870703845376.0000 - accuracy: 0.1329 - val_loss: -844884113675517952.0000 - val_accuracy: 0.1381\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -900107566216904704.0000 - accuracy: 0.1329 - val_loss: -893390374804914176.0000 - val_accuracy: 0.1381\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -951154729998614528.0000 - accuracy: 0.1329 - val_loss: -943424476060581888.0000 - val_accuracy: 0.1381\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1004301892269899776.0000 - accuracy: 0.1329 - val_loss: -995745492782546944.0000 - val_accuracy: 0.1381\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1059572967408664576.0000 - accuracy: 0.1329 - val_loss: -1050091741203398656.0000 - val_accuracy: 0.1381\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -1117055985064607744.0000 - accuracy: 0.1329 - val_loss: -1106723668139966464.0000 - val_accuracy: 0.1381\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -1176780906929586176.0000 - accuracy: 0.1329 - val_loss: -1165598736236150784.0000 - val_accuracy: 0.1381\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1238920906084974592.0000 - accuracy: 0.1329 - val_loss: -1226607337926557696.0000 - val_accuracy: 0.1381\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1303516664461000704.0000 - accuracy: 0.1329 - val_loss: -1289923264767852544.0000 - val_accuracy: 0.1381\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -1370489429537325056.0000 - accuracy: 0.1329 - val_loss: -1356112627809386496.0000 - val_accuracy: 0.1381\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1440065700709269504.0000 - accuracy: 0.1329 - val_loss: -1424441640478572544.0000 - val_accuracy: 0.1381\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -1512142123883823104.0000 - accuracy: 0.1329 - val_loss: -1495224350784094208.0000 - val_accuracy: 0.1381\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1586877578491199488.0000 - accuracy: 0.1329 - val_loss: -1568500753461411840.0000 - val_accuracy: 0.1381\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1664321679993602048.0000 - accuracy: 0.1329 - val_loss: -1644844106385457152.0000 - val_accuracy: 0.1381\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -1744577095289274368.0000 - accuracy: 0.1329 - val_loss: -1723685274849902592.0000 - val_accuracy: 0.1381\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -1827660591930540032.0000 - accuracy: 0.1329 - val_loss: -1804914307691970560.0000 - val_accuracy: 0.1381\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -1913549629929029632.0000 - accuracy: 0.1329 - val_loss: -1889846358257434624.0000 - val_accuracy: 0.1381\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -2002551660223660032.0000 - accuracy: 0.1329 - val_loss: -1976815803869167616.0000 - val_accuracy: 0.1381\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -2094615692962693120.0000 - accuracy: 0.1329 - val_loss: -2067077187294461952.0000 - val_accuracy: 0.1381\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -2189761656794382336.0000 - accuracy: 0.1329 - val_loss: -2160666792417034240.0000 - val_accuracy: 0.1381\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 1s 9ms/step - loss: -2288181553936728064.0000 - accuracy: 0.1329 - val_loss: -2257063450725318656.0000 - val_accuracy: 0.1381\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -2389849545866477568.0000 - accuracy: 0.1329 - val_loss: -2357027199632015360.0000 - val_accuracy: 0.1381\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -2494873797040013312.0000 - accuracy: 0.1329 - val_loss: -2459834285608140800.0000 - val_accuracy: 0.1381\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 1s 13ms/step - loss: -2603222696498036736.0000 - accuracy: 0.1329 - val_loss: -2566060852746649600.0000 - val_accuracy: 0.1381\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 1s 12ms/step - loss: -2715083985850990592.0000 - accuracy: 0.1329 - val_loss: -2675632684012666880.0000 - val_accuracy: 0.1381\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -2830402414639579136.0000 - accuracy: 0.1329 - val_loss: -2788749890522447872.0000 - val_accuracy: 0.1381\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -2949362151061454848.0000 - accuracy: 0.1329 - val_loss: -2905465523712032768.0000 - val_accuracy: 0.1381\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -3071994531198009344.0000 - accuracy: 0.1329 - val_loss: -3025880463773270016.0000 - val_accuracy: 0.1381\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -3198439742781784064.0000 - accuracy: 0.1329 - val_loss: -3149908673921286144.0000 - val_accuracy: 0.1381\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -3328833025742995456.0000 - accuracy: 0.1329 - val_loss: -3276662298516652032.0000 - val_accuracy: 0.1381\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 1s 11ms/step - loss: -3462891805593305088.0000 - accuracy: 0.1329 - val_loss: -3408874448588111872.0000 - val_accuracy: 0.1381\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -3601189752524505088.0000 - accuracy: 0.1329 - val_loss: -3543920864758071296.0000 - val_accuracy: 0.1381\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 1s 10ms/step - loss: -3743523731763363840.0000 - accuracy: 0.1329 - val_loss: -3683426350334476288.0000 - val_accuracy: 0.1381\n"
          ]
        }
      ],
      "source": [
        "model_2 = Sequential([\n",
        "    Dense(1000, activation='relu', input_shape=(12,)),\n",
        "    Dense(1000, activation='relu'),\n",
        "    Dense(1000, activation='relu'),\n",
        "    Dense(1000, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "hist_2 = model_2.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=20,\n",
        "          validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 2s 17ms/step - loss: -113428376.0000 - accuracy: 0.1324 - val_loss: -919057088.0000 - val_accuracy: 0.1381\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 1s 13ms/step - loss: -27779553280.0000 - accuracy: 0.1329 - val_loss: -102234824704.0000 - val_accuracy: 0.1381\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 2s 14ms/step - loss: -518103433216.0000 - accuracy: 0.1329 - val_loss: -1273215057920.0000 - val_accuracy: 0.1381\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -3568957915136.0000 - accuracy: 0.1329 - val_loss: -6864520609792.0000 - val_accuracy: 0.1381\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -14338104492032.0000 - accuracy: 0.1329 - val_loss: -23624354365440.0000 - val_accuracy: 0.1381\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -42260678836224.0000 - accuracy: 0.1329 - val_loss: -63195439955968.0000 - val_accuracy: 0.1381\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 2s 14ms/step - loss: -100828417359872.0000 - accuracy: 0.1329 - val_loss: -140515106357248.0000 - val_accuracy: 0.1381\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 1s 13ms/step - loss: -209810024824832.0000 - accuracy: 0.1329 - val_loss: -277858178039808.0000 - val_accuracy: 0.1381\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -392355731472384.0000 - accuracy: 0.1329 - val_loss: -500456300216320.0000 - val_accuracy: 0.1381\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -679078487130112.0000 - accuracy: 0.1329 - val_loss: -836526820818944.0000 - val_accuracy: 0.1381\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -1102042571472896.0000 - accuracy: 0.1329 - val_loss: -1324644552409088.0000 - val_accuracy: 0.1381\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -1701532093382656.0000 - accuracy: 0.1329 - val_loss: -2001598507122688.0000 - val_accuracy: 0.1381\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 2s 14ms/step - loss: -2517695333400576.0000 - accuracy: 0.1329 - val_loss: -2909893224824832.0000 - val_accuracy: 0.1381\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 2s 14ms/step - loss: -3595102106681344.0000 - accuracy: 0.1329 - val_loss: -4101058380955648.0000 - val_accuracy: 0.1381\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -4998831368306688.0000 - accuracy: 0.1329 - val_loss: -5624408924225536.0000 - val_accuracy: 0.1381\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -6783822460878848.0000 - accuracy: 0.1329 - val_loss: -7540104461549568.0000 - val_accuracy: 0.1381\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 2s 14ms/step - loss: -8977278365073408.0000 - accuracy: 0.1329 - val_loss: -9905280137560064.0000 - val_accuracy: 0.1381\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 2s 14ms/step - loss: -11661181953507328.0000 - accuracy: 0.1329 - val_loss: -12757945875955712.0000 - val_accuracy: 0.1381\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -14952976959406080.0000 - accuracy: 0.1329 - val_loss: -16199200375046144.0000 - val_accuracy: 0.1381\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 1s 14ms/step - loss: -18884116502020096.0000 - accuracy: 0.1329 - val_loss: -20287980249808896.0000 - val_accuracy: 0.1381\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model_3 = Sequential([\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(12,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
        "])\n",
        "\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "hist_3 = model_3.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=20,\n",
        "          validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP5hCxOXwciEMhpBDw9LkHy",
      "include_colab_link": true,
      "name": "TestingDNNs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
